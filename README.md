# Eval-Flow: AI Agent Evaluation Platform

<div align="center">

![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=next.js&logoColor=white)
![Supabase](https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white)
![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&logo=typescript&logoColor=white)
![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white)

**Enterprise-grade AI Agent Evaluation Platform with real-time analytics and multi-tenant security**

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/Allen-Pinto/Eval-Flow)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

## ðŸ“‹ Submission Package

### ðŸš€ Deployed Application
- **Live URL**: [https://eval-flow.vercel.app](https://eval-flow.vercel.app)
- **Test Credentials**:
  - Email: `test@example.com`
  - Password: `password123`

### ðŸ“‚ GitHub Repository
- **Public Repository**: [https://github.com/Allen-Pinto/Eval-Flow](https://github.com/Allen-Pinto/Eval-Flow)
- **Features**: Complete authentication, dashboard, RLS policies, and sample data

### ðŸ› ï¸ AI Tools Used
- **Claude Code**: Primary development assistant for architecture design, code generation, and debugging
- **Usage**: 
  - Generated database schema and RLS policies
  - Assisted with Next.js 14 App Router implementation
  - Helped debug authentication flows and deployment issues
  - Created comprehensive documentation and seed scripts

## Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Database Schema](#database-schema)
- [Quick Start](#quick-start)
- [Installation](#installation)
- [Configuration](#configuration)
- [API Documentation](#api-documentation)
- [Development](#development)
- [Deployment](#deployment)
- [Seed Data](#seed-data)
- [Contributing](#contributing)
- [License](#license)

## Overview

Eval-Flow is a comprehensive evaluation framework designed for monitoring and analyzing AI agent performance. Built with modern web technologies, it provides real-time dashboards, configurable evaluation policies, and enterprise-grade security for teams deploying AI solutions at scale.

## Features

### Core Capabilities
- **Real-time Analytics Dashboard** - Interactive charts with 7/30-day trend analysis
- **Multi-Tenant Architecture** - Secure data isolation with Row-Level Security
- **Configurable Evaluation Policies** - Always run or sampled evaluation modes
- **Automated PII Protection** - Built-in sensitive data redaction
- **RESTful API** - Simple integration for evaluation data ingestion

### Technical Features
- **Performance Optimized** - Indexed queries with sub-50ms response times
- **Type-Safe Development** - Full TypeScript implementation
- **Responsive Design** - Mobile-optimized interface
- **Production Ready** - Comprehensive error handling and logging

## Architecture

### Technology Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| Frontend | Next.js 14 | React framework with App Router |
| Styling | Tailwind CSS | Utility-first CSS framework |
| Database | PostgreSQL | Primary data storage |
| Backend | Supabase | BaaS with Auth and RLS |
| Charts | Recharts | Data visualization library |
| Deployment | Vercel | Serverless deployment platform |

### System Architecture

```
Client Layer
â”œâ”€â”€ Web Application (Next.js)
â”œâ”€â”€ Authentication (Supabase Auth)
â””â”€â”€ Real-time Dashboard

API Layer
â”œâ”€â”€ REST Endpoints (/api/*)
â”œâ”€â”€ Evaluation Ingestion
â””â”€â”€ Metrics Calculation

Data Layer
â”œâ”€â”€ PostgreSQL Database
â”œâ”€â”€ Row-Level Security
â””â”€â”€ Automated Backups
```

## Database Schema

### Tables Structure

#### Profiles Table
```sql
CREATE TABLE profiles (
  id UUID PRIMARY KEY REFERENCES auth.users(id) ON DELETE CASCADE,
  email TEXT UNIQUE NOT NULL,
  full_name TEXT,
  organization TEXT,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);
```

#### Evaluation Configs Table
```sql
CREATE TABLE evaluation_configs (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL REFERENCES profiles(id) ON DELETE CASCADE,
  run_policy TEXT CHECK (run_policy IN ('always', 'sampled')),
  sample_rate_pct INT CHECK (sample_rate_pct >= 0 AND sample_rate_pct <= 100),
  obfuscate_pii BOOLEAN DEFAULT false,
  max_eval_per_day INT DEFAULT 1000,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  UNIQUE(user_id)
);
```

#### Evaluations Table
```sql
CREATE TABLE evaluations (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL REFERENCES profiles(id) ON DELETE CASCADE,
  interaction_id TEXT NOT NULL,
  prompt TEXT NOT NULL,
  response TEXT NOT NULL,
  score NUMERIC CHECK (score >= 0 AND score <= 100),
  latency_ms INT NOT NULL,
  flags TEXT[] DEFAULT '{}',
  pii_tokens_redacted INT DEFAULT 0,
  prompt_masked TEXT,
  response_masked TEXT,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);
```

#### Audit Logs Table
```sql
CREATE TABLE audit_logs (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  user_id UUID NOT NULL REFERENCES profiles(id) ON DELETE CASCADE,
  action TEXT NOT NULL,
  resource_type TEXT,
  resource_id UUID,
  details JSONB,
  created_at TIMESTAMP DEFAULT NOW()
);
```

### Row Level Security (RLS) Policies

All tables have RLS enabled with the following policies:

#### Profiles Policies
- Users can view and update only their own profile

#### Evaluation Configs Policies  
- Users can view, insert, and update only their own configs

#### Evaluations Policies
- Users can view, insert, and update only their own evaluations

#### Audit Logs Policies
- Users can view and insert only their own audit logs

## Quick Start

### Prerequisites
- Node.js 18+ 
- Supabase account
- GitHub account

### One-Click Deployment

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/Allen-Pinto/Eval-Flow)

## Installation

### Local Development Setup

1. **Clone the repository**
```bash
git clone https://github.com/Allen-Pinto/Eval-Flow.git
cd Eval-Flow
```

2. **Install dependencies**
```bash
npm install
```

3. **Environment configuration**
```bash
cp .env.example .env.local
```

4. **Set up environment variables**
```env
# Supabase Configuration
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_KEY=your_supabase_service_key

# Application Settings
NEXT_PUBLIC_SITE_URL=http://localhost:3000
```

5. **Run development server**
```bash
npm run dev
```

Visit `http://localhost:3000` to access the application.

## Configuration

### Supabase Setup

1. **Create a new project** at [supabase.com](https://supabase.com)
2. **Run database schema** from the SQL below
3. **Configure authentication** settings
4. **Set up Row-Level Security** policies

### Complete Database Setup Script

```sql
-- Enable extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";

-- Create tables (see Database Schema section above)

-- Enable Row Level Security
ALTER TABLE profiles ENABLE ROW LEVEL SECURITY;
ALTER TABLE evaluation_configs ENABLE ROW LEVEL SECURITY;
ALTER TABLE evaluations ENABLE ROW LEVEL SECURITY;
ALTER TABLE audit_logs ENABLE ROW LEVEL SECURITY;

-- Create RLS Policies (see RLS Policies section above)

-- Create indexes for performance
CREATE INDEX evaluations_user_id_created_at ON evaluations(user_id, created_at DESC);
CREATE INDEX evaluations_user_id_score ON evaluations(user_id, score);
CREATE INDEX evaluations_user_id_latency ON evaluations(user_id, latency_ms);
CREATE INDEX evaluations_interaction_id ON evaluations(interaction_id);
CREATE INDEX audit_logs_user_id ON audit_logs(user_id, created_at DESC);
```

## Seed Data

### Generate Sample Data for Testing

Run this SQL script in your Supabase SQL Editor to create test data:

```sql
-- Seed script: Generate sample evaluation data for testing
INSERT INTO evaluations (user_id, interaction_id, prompt, response, score, latency_ms, pii_tokens_redacted, created_at)
SELECT 
  '{{USER_ID}}'::uuid,
  'interaction_' || seq,
  'Test prompt ' || seq || ' - What is machine learning?',
  'Test response ' || seq || ' - Machine learning is a subset of AI that enables systems to learn and improve from experience without explicit programming.',
  (RANDOM() * 40 + 60)::numeric(4,1), -- Random score between 60-100
  (RANDOM() * 200 + 100)::integer, -- Random latency between 100-300ms
  (RANDOM() * 5)::integer, -- Random PII redactions 0-4
  NOW() - (seq * INTERVAL '1 hour')
FROM GENERATE_SERIES(1, 50) seq;

-- Create sample evaluation config
INSERT INTO evaluation_configs (user_id, run_policy, sample_rate_pct, obfuscate_pii, max_eval_per_day)
VALUES ('{{USER_ID}}', 'always', 100, true, 1000)
ON CONFLICT (user_id) DO UPDATE SET
  run_policy = EXCLUDED.run_policy,
  sample_rate_pct = EXCLUDED.sample_rate_pct,
  obfuscate_pii = EXCLUDED.obfuscate_pii,
  max_eval_per_day = EXCLUDED.max_eval_per_day;
```

**Note**: Replace `{{USER_ID}}` with an actual user ID from your `profiles` table.

## API Documentation

### Evaluation Ingestion Endpoint

```http
POST /api/evals/ingest
Authorization: Bearer <user_token>
Content-Type: application/json
```

**Request Body:**
```json
{
  "interaction_id": "string",
  "prompt": "string",
  "response": "string", 
  "score": number,
  "latency_ms": number,
  "flags": ["string"]
}
```

**Response:**
```json
{
  "id": "uuid",
  "status": "success",
  "pii_redacted": number
}
```

### Metrics Endpoint

```http
GET /api/metrics?period=7d|30d
Authorization: Bearer <user_token>
```

**Response:**
```json
{
  "total_evals": number,
  "avg_score": number,
  "avg_latency_ms": number,
  "success_rate_pct": number,
  "pii_redactions_total": number,
  "trend_daily": array
}
```

## Development

### Project Structure

```
eval-flow/
â”œâ”€â”€ app/                    # Next.js app directory
â”‚   â”œâ”€â”€ auth/              # Authentication pages
â”‚   â”œâ”€â”€ dashboard/         # Dashboard pages
â”‚   â””â”€â”€ api/               # API routes
â”œâ”€â”€ components/            # React components
â”‚   â”œâ”€â”€ Charts/           # Data visualization
â”‚   â””â”€â”€ UI/               # Reusable UI components
â”œâ”€â”€ lib/                   # Utility libraries
â”‚   â”œâ”€â”€ supabase.ts       # Supabase client
â”‚   â””â”€â”€ metrics.ts        # Metrics calculation
â””â”€â”€ supabase/             # Database migrations
    â””â”€â”€ migrations/
```

### Available Scripts

```bash
npm run dev          # Start development server
npm run build        # Create production build
npm run start        # Start production server
npm run lint         # Run ESLint
npm run type-check   # Run TypeScript compiler
```

## Deployment

### Vercel Deployment

1. **Connect repository** to Vercel
2. **Configure environment variables**
3. **Deploy automatically** on git push

### Environment Variables for Production

**Required Variables:**
```env
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
NEXT_PUBLIC_SITE_URL=https://your-app.vercel.app
```

## Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Workflow

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

### Code Standards

- TypeScript for type safety
- ESLint for code quality
- Prettier for code formatting
- Conventional commits for commit messages

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Support

- [Documentation](https://github.com/Allen-Pinto/Eval-Flow/wiki)
- [Issue Tracker](https://github.com/Allen-Pinto/Eval-Flow/issues)
- [Discussions](https://github.com/Allen-Pinto/Eval-Flow/discussions)

---

<div align="center">

**Eval-Flow** - *Evaluate your AI agents with confidence*

[Live Demo](https://eval-flow.vercel.app) â€¢ [Documentation](https://github.com/Allen-Pinto/Eval-Flow/wiki) â€¢ [Report Bug](https://github.com/Allen-Pinto/Eval-Flow/issues)

*Built with Claude Code AI assistance*

</div>
```
